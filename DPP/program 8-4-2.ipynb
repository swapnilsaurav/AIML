{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78bad4ff-730b-4887-a958-891574ddfc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold, SequentialFeatureSelector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4457b0d5-d73a-4ad5-8401-2aee88e8c616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (426, 30)\n",
      "Test shape : (143, 30)\n"
     ]
    }
   ],
   "source": [
    "#Load data (Breast Cancer) and split\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target, name=\"target\")  # 1 = benign, 0 = malignant (dataset-specific)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape :\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "147a0df3-4a48-4474-b936-85c3cb843031",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper: evaluate pipeline (Accuracy + AUC + Runtime)\n",
    "def evaluate_model(name, model, Xtr, ytr, Xte, yte):\n",
    "    start = time.time()\n",
    "    model.fit(Xtr, ytr)\n",
    "    fit_time = time.time() - start\n",
    "    \n",
    "    proba = model.predict_proba(Xte)[:, 1]\n",
    "    pred = (proba >= 0.5).astype(int)\n",
    "    \n",
    "    acc = accuracy_score(yte, pred)\n",
    "    auc = roc_auc_score(yte, proba)\n",
    "    \n",
    "    return {\n",
    "        \"Stage\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"AUC\": auc,\n",
    "        \"Fit_time_sec\": fit_time\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ec8bdb2-7cdd-4545-a2eb-5b1bd1468c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Stage': 'Baseline (All features)',\n",
       " 'Accuracy': 0.986013986013986,\n",
       " 'AUC': 0.9976939203354298,\n",
       " 'Fit_time_sec': 0.012922525405883789}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Baseline model (no feature selection)\n",
    "baseline_model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, solver=\"liblinear\"))\n",
    "])\n",
    "\n",
    "baseline_result = evaluate_model(\n",
    "    \"Baseline (All features)\",\n",
    "    baseline_model,\n",
    "    X_train, y_train,\n",
    "    X_test, y_test\n",
    ")\n",
    "\n",
    "baseline_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cff3e5-c44b-4e00-b2db-5c6d61adce31",
   "metadata": {},
   "source": [
    "<h2> Stage 1 — FILTER METHODS (fast noise removal)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1dafc047-7b41-4a0d-a3dd-ec5be92a23aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After VarianceThreshold: 30 features kept\n"
     ]
    }
   ],
   "source": [
    "# Stage 1A) Variance Threshold (remove near-constant features)\n",
    "var_selector = VarianceThreshold(threshold=0.0)  # remove only zero-variance features\n",
    "X_train_var = var_selector.fit_transform(X_train)\n",
    "X_test_var = var_selector.transform(X_test)\n",
    "\n",
    "kept_var_mask = var_selector.get_support()\n",
    "kept_var_features = X_train.columns[kept_var_mask]\n",
    "\n",
    "print(\"After VarianceThreshold:\", X_train_var.shape[1], \"features kept\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f8553bf-c18c-4811-8e4f-811bbcace9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After correlation pruning: 23 features kept\n",
      "Dropped due to high correlation: 7\n"
     ]
    }
   ],
   "source": [
    "# Stage 1B) Correlation pruning (remove redundant features)\n",
    "def correlation_prune(df, threshold=0.95):\n",
    "    corr = df.corr().abs()\n",
    "    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "    to_drop = [col for col in upper.columns if any(upper[col] > threshold)]\n",
    "    kept = [c for c in df.columns if c not in to_drop]\n",
    "    return kept, to_drop\n",
    "\n",
    "X_train_var_df = pd.DataFrame(X_train_var, columns=kept_var_features, index=X_train.index)\n",
    "X_test_var_df  = pd.DataFrame(X_test_var,  columns=kept_var_features, index=X_test.index)\n",
    "\n",
    "kept_corr_features, dropped_corr_features = correlation_prune(X_train_var_df, threshold=0.95)\n",
    "\n",
    "X_train_filter = X_train_var_df[kept_corr_features]\n",
    "X_test_filter  = X_test_var_df[kept_corr_features]\n",
    "\n",
    "print(\"After correlation pruning:\", X_train_filter.shape[1], \"features kept\")\n",
    "print(\"Dropped due to high correlation:\", len(dropped_corr_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb082796-f0c0-4699-893d-12f85e630435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Stage': 'Stage 1: Filter (Variance + Corr prune)',\n",
       " 'Accuracy': 0.9790209790209791,\n",
       " 'AUC': 0.9962264150943396,\n",
       " 'Fit_time_sec': 0.009938240051269531}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate after Filter stage\n",
    "filter_model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, solver=\"liblinear\"))\n",
    "])\n",
    "\n",
    "filter_result = evaluate_model(\n",
    "    \"Stage 1: Filter (Variance + Corr prune)\",\n",
    "    filter_model,\n",
    "    X_train_filter, y_train,\n",
    "    X_test_filter, y_test\n",
    ")\n",
    "\n",
    "filter_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7614f293-b236-434a-bfaf-c9114cf1e85e",
   "metadata": {},
   "source": [
    "<h2> Stage 2 — WRAPPER METHOD (performance refinement)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c79c2ad-11be-4d70-a528-c58578450114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapper selected features: 10\n",
      "SFS time (sec): 20.266\n",
      "Selected features:\n",
      " ['mean radius', 'mean symmetry', 'radius error', 'compactness error', 'concave points error', 'fractal dimension error', 'worst texture', 'worst smoothness', 'worst concave points', 'worst symmetry']\n"
     ]
    }
   ],
   "source": [
    "#Sequential Forward Selection (SFS) with Logistic Regression.\n",
    "wrapper_estimator = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, solver=\"liblinear\"))\n",
    "])\n",
    "\n",
    "# pick a target number of features (you can tune this)\n",
    "n_select = min(10, X_train_filter.shape[1])\n",
    "\n",
    "sfs = SequentialFeatureSelector(\n",
    "    estimator=wrapper_estimator,\n",
    "    n_features_to_select=n_select,\n",
    "    direction=\"forward\",\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "sfs.fit(X_train_filter, y_train)\n",
    "sfs_time = time.time() - start\n",
    "\n",
    "sfs_mask = sfs.get_support()\n",
    "sfs_features = X_train_filter.columns[sfs_mask]\n",
    "\n",
    "X_train_wrap = X_train_filter[sfs_features]\n",
    "X_test_wrap  = X_test_filter[sfs_features]\n",
    "\n",
    "print(\"Wrapper selected features:\", len(sfs_features))\n",
    "print(\"SFS time (sec):\", round(sfs_time, 3))\n",
    "print(\"Selected features:\\n\", list(sfs_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8865bfe-228c-4920-9574-8f360e2a813e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Stage': 'Stage 2: Wrapper (SFS top 10)',\n",
       " 'Accuracy': 0.972027972027972,\n",
       " 'AUC': 0.9958071278825996,\n",
       " 'Fit_time_sec': 0.007886648178100586,\n",
       " 'Selection_time_sec': 20.265742540359497}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate after Wrapper stage\n",
    "wrapper_model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, solver=\"liblinear\"))\n",
    "])\n",
    "\n",
    "wrapper_result = evaluate_model(\n",
    "    f\"Stage 2: Wrapper (SFS top {len(sfs_features)})\",\n",
    "    wrapper_model,\n",
    "    X_train_wrap, y_train,\n",
    "    X_test_wrap, y_test\n",
    ")\n",
    "\n",
    "# include selection time too\n",
    "wrapper_result[\"Selection_time_sec\"] = sfs_time\n",
    "wrapper_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1cd92d-4394-4970-b539-cdc0ad4d1fab",
   "metadata": {},
   "source": [
    "<h2>Stage 3 — EMBEDDED METHOD (final selection)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ed5e50b-8619-4be6-809f-a4af752719f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Stage': 'Stage 3: Embedded (L1 Logistic Regression)',\n",
       " 'Accuracy': 0.965034965034965,\n",
       " 'AUC': 0.9955974842767296,\n",
       " 'Fit_time_sec': 0.0094451904296875}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        max_iter=3000,\n",
    "        solver=\"liblinear\",   # supports L1\n",
    "        penalty=\"l1\",\n",
    "        C=1.0                 # inverse of regularization strength (tune if needed)\n",
    "    ))\n",
    "])\n",
    "\n",
    "embedded_result = evaluate_model(\n",
    "    \"Stage 3: Embedded (L1 Logistic Regression)\",\n",
    "    embedded_model,\n",
    "    X_train_wrap, y_train,\n",
    "    X_test_wrap, y_test\n",
    ")\n",
    "\n",
    "embedded_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b192a4f0-ec85-4784-946a-2ae1ea819706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final features kept by L1: 7\n",
      "Kept: ['mean radius', 'radius error', 'compactness error', 'worst texture', 'worst smoothness', 'worst concave points', 'worst symmetry']\n",
      "Dropped: ['mean symmetry', 'concave points error', 'fractal dimension error']\n"
     ]
    }
   ],
   "source": [
    "#Inspect which features survived L1 (non-zero coefficients)\n",
    "# Fit on training to read coefficients\n",
    "embedded_model.fit(X_train_wrap, y_train)\n",
    "\n",
    "coef = embedded_model.named_steps[\"clf\"].coef_.ravel()\n",
    "final_features = X_train_wrap.columns[coef != 0]\n",
    "dropped_features = X_train_wrap.columns[coef == 0]\n",
    "\n",
    "print(\"Final features kept by L1:\", len(final_features))\n",
    "print(\"Kept:\", list(final_features))\n",
    "print(\"Dropped:\", list(dropped_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dab15f2c-6d6d-4aa5-9f20-8b2fb9a3f5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stage</th>\n",
       "      <th>Num_features</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Fit_time_sec</th>\n",
       "      <th>Selection_time_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline (All features)</td>\n",
       "      <td>30</td>\n",
       "      <td>0.986014</td>\n",
       "      <td>0.997694</td>\n",
       "      <td>0.012923</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stage 1: Filter (Variance + Corr prune)</td>\n",
       "      <td>23</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.996226</td>\n",
       "      <td>0.009938</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stage 2: Wrapper (SFS top 10)</td>\n",
       "      <td>10</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.995807</td>\n",
       "      <td>0.007887</td>\n",
       "      <td>20.265743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stage 3: Embedded (L1 Logistic Regression)</td>\n",
       "      <td>7</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.995597</td>\n",
       "      <td>0.009445</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Stage  Num_features  Accuracy  \\\n",
       "0                     Baseline (All features)            30  0.986014   \n",
       "1     Stage 1: Filter (Variance + Corr prune)            23  0.979021   \n",
       "2               Stage 2: Wrapper (SFS top 10)            10  0.972028   \n",
       "3  Stage 3: Embedded (L1 Logistic Regression)             7  0.965035   \n",
       "\n",
       "        AUC  Fit_time_sec  Selection_time_sec  \n",
       "0  0.997694      0.012923                 NaN  \n",
       "1  0.996226      0.009938                 NaN  \n",
       "2  0.995807      0.007887           20.265743  \n",
       "3  0.995597      0.009445                 NaN  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final comparison\n",
    "\n",
    "results = []\n",
    "\n",
    "results.append({**baseline_result, \"Num_features\": X_train.shape[1]})\n",
    "results.append({**filter_result,   \"Num_features\": X_train_filter.shape[1]})\n",
    "results.append({**wrapper_result,  \"Num_features\": X_train_wrap.shape[1]})\n",
    "results.append({**embedded_result, \"Num_features\": len(final_features)})\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Make it clean\n",
    "cols = [\"Stage\", \"Num_features\", \"Accuracy\", \"AUC\", \"Fit_time_sec\"]\n",
    "extra_cols = [c for c in df_results.columns if c not in cols]\n",
    "df_results = df_results[cols + extra_cols]\n",
    "\n",
    "df_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b74fbe9-b602-4867-802b-dd65e2135afe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "974e024f-e920-44f3-94cd-8b68b9717326",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Automating Pre-processing with Pipelines in scikit-learn (Numeric-focused)\n",
    "\n",
    "Dataset: retail_sales_numeria_week4.csv\n",
    "Target : target_sales\n",
    "\n",
    "What this program demonstrates:\n",
    "1) Load dataset + apply simple validity rules (0 income -> missing, negative marketing spend -> missing)\n",
    "2) Train/Test split FIRST (avoid leakage)\n",
    "3) Automatically detect skewed numeric features from TRAIN split only\n",
    "4) Build a ColumnTransformer that:\n",
    "   - Applies (Impute -> PowerTransform -> Scale) to skewed numeric columns\n",
    "   - Applies (Impute -> Scale) to non-skewed numeric columns\n",
    "5) Wrap everything inside a single Pipeline with a model\n",
    "6) Evaluate baseline vs automated pipeline\n",
    "7) Show how to reuse the same pipeline for future data (predict)\n",
    "\n",
    "Why PowerTransformer?\n",
    "- Works for many skew patterns\n",
    "- Doesn't require strictly positive values (Yeo-Johnson)\n",
    "- Great for \"automated\" preprocessing across many columns\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import Ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cb10596-4fcc-4997-ac65-a77b1d27eb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 8000\n",
      "Numeric features: ['annual_income', 'monthly_spend', 'avg_basket_value', 'marketing_spend']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1) Load dataset\n",
    "# -----------------------------\n",
    "df = pd.read_csv(\"D:/datasets/dpp/retail_sales_numeria_week4.csv\")\n",
    "\n",
    "TARGET = \"target_sales\"\n",
    "ID_COLS = [\"customer_id\", \"store_id\"]\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Validity cleaning (safe business rules; OK before split)\n",
    "# -----------------------------\n",
    "df_clean = df.copy()\n",
    "df_clean.loc[df_clean[\"annual_income\"] <= 0, \"annual_income\"] = np.nan\n",
    "df_clean.loc[df_clean[\"marketing_spend\"] < 0, \"marketing_spend\"] = np.nan\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Select numeric features\n",
    "# -----------------------------\n",
    "numeric_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_features = [c for c in numeric_cols if c not in ID_COLS + [TARGET]]\n",
    "\n",
    "X = df_clean[numeric_features]\n",
    "y = df_clean[TARGET]\n",
    "\n",
    "print(\"Rows:\", len(df_clean))\n",
    "print(\"Numeric features:\", numeric_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d3234ec-0937-4fc5-8d9a-e09baa0f501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 4) Split train/test FIRST (avoid leakage)\n",
    "# -----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "672c4792-a14d-4fc3-aadd-9b72b8194c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skewness (train) top 10 by |skew|:\n",
      "marketing_spend     5.209\n",
      "monthly_spend       5.137\n",
      "annual_income       4.150\n",
      "avg_basket_value    2.679\n",
      "dtype: float64\n",
      "\n",
      "Skewed cols (|skew| >= 1.0): ['annual_income', 'monthly_spend', 'avg_basket_value', 'marketing_spend']\n",
      "Non-skewed cols: []\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 5) Automatically detect skewed columns (TRAIN only)\n",
    "# -----------------------------\n",
    "# Rule: |skew| >= 1.0 => \"skewed\"\n",
    "SKEW_THRESHOLD = 1.0\n",
    "\n",
    "train_skew = X_train.skew(numeric_only=True)\n",
    "skewed_cols = train_skew[train_skew.abs() >= SKEW_THRESHOLD].index.tolist()\n",
    "non_skewed_cols = [c for c in numeric_features if c not in skewed_cols]\n",
    "\n",
    "print(\"\\nSkewness (train) top 10 by |skew|:\")\n",
    "print(train_skew.reindex(train_skew.abs().sort_values(ascending=False).index).head(10).round(3))\n",
    "\n",
    "print(\"\\nSkewed cols (|skew| >= 1.0):\", skewed_cols)\n",
    "print(\"Non-skewed cols:\", non_skewed_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3736d418-bcaa-4003-9026-d3205e12b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 6) Build preprocessing pipelines\n",
    "# -----------------------------\n",
    "# Skewed numeric pipeline: Impute -> PowerTransform -> Scale\n",
    "skewed_num_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"power\", PowerTransformer(method=\"yeo-johnson\", standardize=False)),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Non-skewed numeric pipeline: Impute -> Scale\n",
    "normal_num_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# ColumnTransformer: different logic per column group\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"skewed\", skewed_num_pipe, skewed_cols),\n",
    "        (\"normal\", normal_num_pipe, non_skewed_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17b35cc5-5f86-459b-9d71-4c5a8363024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 7) Wrap into a full ML pipeline (preprocess + model)\n",
    "# -----------------------------\n",
    "model = Ridge(alpha=1.0, random_state=42)\n",
    "\n",
    "full_pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", model)\n",
    "])\n",
    "\n",
    "# -----------------------------\n",
    "# 8) Baseline pipeline for comparison (Impute + Scale for ALL numeric)\n",
    "# -----------------------------\n",
    "baseline_preprocess = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "baseline_pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", baseline_preprocess),\n",
    "    (\"model\", Ridge(alpha=1.0, random_state=42))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa1561be-8e0e-405a-a61d-98fe6c9286ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 9) Evaluation helper\n",
    "# -----------------------------\n",
    "def evaluate(pipe, name: str):\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    pred_tr = pipe.predict(X_train)\n",
    "    pred_te = pipe.predict(X_test)\n",
    "\n",
    "    mae_tr = mean_absolute_error(y_train, pred_tr)\n",
    "    mae_te = mean_absolute_error(y_test, pred_te)\n",
    "\n",
    "    r2_tr = r2_score(y_train, pred_tr)\n",
    "    r2_te = r2_score(y_test, pred_te)\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Train MAE: {mae_tr:,.2f} | Test MAE: {mae_te:,.2f} | Gap(Test-Train): {mae_te - mae_tr:,.2f}\")\n",
    "    print(f\"Train R² : {r2_tr:,.4f} | Test R² : {r2_te:,.4f} | Gap(Train-Test): {r2_tr - r2_te:,.4f}\")\n",
    "\n",
    "    return pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f3bca7b-0b31-4bb1-a19b-a1f9e79ba98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Baseline: Impute+Scale (All Numeric) ===\n",
      "Train MAE: 609.29 | Test MAE: 597.77 | Gap(Test-Train): -11.52\n",
      "Train R² : 0.6178 | Test R² : 0.6215 | Gap(Train-Test): -0.0037\n",
      "\n",
      "=== Automated: Skew-aware Pipelines (Power+Scale for skewed cols) ===\n",
      "Train MAE: 56.54 | Test MAE: 57.65 | Gap(Test-Train): 1.11\n",
      "Train R² : 0.9850 | Test R² : 0.9811 | Gap(Train-Test): 0.0039\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 10) Run + compare\n",
    "# -----------------------------\n",
    "baseline_pipeline = evaluate(baseline_pipeline, \"Baseline: Impute+Scale (All Numeric)\")\n",
    "full_pipeline = evaluate(full_pipeline, \"Automated: Skew-aware Pipelines (Power+Scale for skewed cols)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e24db6dd-e2ea-4e89-a9cb-cd228fd38b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example predictions on new data (5 rows):\n",
      "   predicted_target_sales\n",
      "0                18550.45\n",
      "1                17296.60\n",
      "2                19180.62\n",
      "3                20677.09\n",
      "4                19819.52\n",
      "\n",
      "Done. This pipeline can now be saved and reused consistently in production.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 11) Show how to reuse the same pipeline for NEW data\n",
    "# -----------------------------\n",
    "# Example: take 5 rows as \"new incoming\" data (in real life, this could be new customers)\n",
    "new_data = X_test.sample(5, random_state=7)\n",
    "pred_new = full_pipeline.predict(new_data)\n",
    "\n",
    "print(\"\\nExample predictions on new data (5 rows):\")\n",
    "print(pd.DataFrame({\"predicted_target_sales\": pred_new.round(2)}))\n",
    "\n",
    "print(\"\\nDone. This pipeline can now be saved and reused consistently in production.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735fc245-cef6-4c40-b0e3-2a81b2be7d21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63e9f2a3-7c4f-4cbe-baf0-94d0eb55ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Consolidated Example: Numeric Data Pre-processing Pipeline\n",
    "Dataset: retail_sales_week4.csv\n",
    "\n",
    "What this program demonstrates (end-to-end):\n",
    "1) Load dataset\n",
    "2) Split train/test FIRST (avoid leakage)\n",
    "3) Detect + fix invalid numeric entries (0 income, negative marketing spend)\n",
    "4) Numeric pipeline:\n",
    "   - Median imputation\n",
    "   - Power transform (Yeo-Johnson) to handle skewness robustly\n",
    "   - Scaling (StandardScaler)\n",
    "5) Train a baseline model vs pipeline model\n",
    "6) Compare performance + generalization gap\n",
    "\n",
    "Note:\n",
    "- We use ColumnTransformer + Pipeline (production-style)\n",
    "- We keep it numeric-only for this module\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import Ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0a312c3-e948-4d8c-ba4f-0b90e2baee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1) Load dataset\n",
    "# -----------------------------\n",
    "df = pd.read_csv(\"D:/datasets/dpp/retail_sales_numeria_week4.csv\")\n",
    "\n",
    "TARGET = \"target_sales\"\n",
    "ID_COLS = [\"customer_id\", \"store_id\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d700d1b-790c-464f-8723-4cb371c3f433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 2) Minimal \"data cleaning\" BEFORE splitting (safe rules that don't use target)\n",
    "#    These are pure business rules / validity rules, not learned from data distribution.\n",
    "# -----------------------------\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Annual income: 0 or negative -> treat as missing\n",
    "df_clean.loc[df_clean[\"annual_income\"] <= 0, \"annual_income\"] = np.nan\n",
    "\n",
    "# Marketing spend: negative -> treat as missing\n",
    "df_clean.loc[df_clean[\"marketing_spend\"] < 0, \"marketing_spend\"] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9e400dc-a85c-4634-816d-e1db7aa130cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 8000\n",
      "Numeric features used: ['annual_income', 'monthly_spend', 'avg_basket_value', 'marketing_spend']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 3) Define features (numeric only)\n",
    "# -----------------------------\n",
    "# Keep numeric columns, drop IDs and target\n",
    "numeric_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_features = [c for c in numeric_cols if c not in ID_COLS + [TARGET]]\n",
    "\n",
    "X = df_clean[numeric_features]\n",
    "y = df_clean[TARGET]\n",
    "\n",
    "print(\"Total rows:\", len(df_clean))\n",
    "print(\"Numeric features used:\", numeric_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "984fc3e1-c346-4945-9bdf-e30fa7e40e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 4) Split train/test FIRST (avoid leakage)\n",
    "# -----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a660e85b-43e6-47cb-9ce5-5c5ba62a8b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 5) Baseline model (NO preprocessing except simple median imputation)\n",
    "#    This is just to compare and show why full preprocessing matters.\n",
    "# -----------------------------\n",
    "baseline_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"model\", Ridge(alpha=1.0, random_state=42))\n",
    "])\n",
    "\n",
    "baseline_pipe.fit(X_train, y_train)\n",
    "pred_train_base = baseline_pipe.predict(X_train)\n",
    "pred_test_base = baseline_pipe.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ccd2cf0-7c45-4ddc-86c2-7336c920f842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 6) Full preprocessing pipeline (Ely the Engineer style)\n",
    "#    Impute -> PowerTransform -> Scale -> Model\n",
    "# -----------------------------\n",
    "numeric_preprocess = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    # Yeo-Johnson handles skew well; works with zeros/negatives (though we cleaned obvious invalids)\n",
    "    (\"power\", PowerTransformer(method=\"yeo-johnson\", standardize=False)),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "full_pipe = Pipeline(steps=[\n",
    "    (\"preprocess\", numeric_preprocess),\n",
    "    (\"model\", Ridge(alpha=1.0, random_state=42))\n",
    "])\n",
    "\n",
    "full_pipe.fit(X_train, y_train)\n",
    "pred_train_full = full_pipe.predict(X_train)\n",
    "pred_test_full = full_pipe.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d804243-fbe3-4296-9a62-89fb46987ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 7) Evaluation helper\n",
    "# -----------------------------\n",
    "def report(name, y_tr, yhat_tr, y_te, yhat_te):\n",
    "    mae_tr = mean_absolute_error(y_tr, yhat_tr)\n",
    "    mae_te = mean_absolute_error(y_te, yhat_te)\n",
    "\n",
    "    r2_tr = r2_score(y_tr, yhat_tr)\n",
    "    r2_te = r2_score(y_te, yhat_te)\n",
    "\n",
    "    # \"Generalization gap\" examples\n",
    "    gap_r2 = r2_tr - r2_te\n",
    "    gap_mae = mae_te - mae_tr\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Train MAE: {mae_tr:,.2f} | Test MAE: {mae_te:,.2f} | (Test-Train MAE): {gap_mae:,.2f}\")\n",
    "    print(f\"Train R² : {r2_tr:,.4f} | Test R² : {r2_te:,.4f} | (Train-Test R²): {gap_r2:,.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d661d1d-dce5-4c1d-8489-57f328e434da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Baseline (Median Impute + Ridge) ===\n",
      "Train MAE: 609.26 | Test MAE: 597.74 | (Test-Train MAE): -11.52\n",
      "Train R² : 0.6178 | Test R² : 0.6215 | (Train-Test R²): -0.0038\n",
      "\n",
      "=== Full Pipeline (Impute + Power + Scale + Ridge) ===\n",
      "Train MAE: 56.54 | Test MAE: 57.65 | (Test-Train MAE): 1.11\n",
      "Train R² : 0.9850 | Test R² : 0.9811 | (Train-Test R²): 0.0039\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 8) Print results\n",
    "# -----------------------------\n",
    "report(\"Baseline (Median Impute + Ridge)\", y_train, pred_train_base, y_test, pred_test_base)\n",
    "report(\"Full Pipeline (Impute + Power + Scale + Ridge)\", y_train, pred_train_full, y_test, pred_test_full)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de9247a4-bec4-47c9-ab47-a7f054f8f1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 skewed features in TRAIN split (|skew|):\n",
      "marketing_spend     5.209\n",
      "monthly_spend       5.137\n",
      "annual_income       4.150\n",
      "avg_basket_value    2.679\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 9) Inspect skewness BEFORE preprocessing (train only)\n",
    "# -----------------------------\n",
    "skew_train = X_train.skew(numeric_only=True).sort_values(key=lambda s: s.abs(), ascending=False)\n",
    "print(\"\\nTop 10 skewed features in TRAIN split (|skew|):\")\n",
    "print(skew_train.head(10).round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbfb37c-7bc3-4f0c-9f83-188e1a717f02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
